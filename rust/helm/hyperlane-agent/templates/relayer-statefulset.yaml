{{- if .Values.hyperlane.relayer.enabled }}
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: {{ include "agent-common.fullname" . }}-relayer
  labels:
    {{- include "agent-common.labels" . | nindent 4 }}
    app.kubernetes.io/component: relayer
spec:
  selector:
    matchLabels:
      {{- include "agent-common.selectorLabels" . | nindent 6 }}
      app.kubernetes.io/component: relayer
  replicas: 1 
  serviceName: {{ include "agent-common.fullname" . }}-relayer
  template:
    metadata:
      annotations:
        checksum/configmap: {{ include (print $.Template.BasePath "/configmap.yaml") . | sha256sum }}
        {{- with .Values.podAnnotations }}
        {{- toYaml . | nindent 8 }}
        {{- end }}
        {{- with .Values.hyperlane.relayer.podAnnotations }}
        {{ toYaml . | nindent 8 }}
        {{- end }}
      labels:
        {{- include "agent-common.labels" . | nindent 8 }}
        app.kubernetes.io/component: relayer
        {{- with .Values.podCommonLabels }}
        {{ toYaml . | nindent 8 }}
        {{- end }}
        {{- with .Values.hyperlane.relayer.podLabels }}
        {{ toYaml . | nindent 8 }}
        {{- end }}
    spec:
      {{- with .Values.imagePullSecrets }}
      imagePullSecrets:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      terminationGracePeriodSeconds: 10
      securityContext:
        {{- toYaml .Values.podSecurityContext | nindent 8 }}
      containers:
      - name: agent
        securityContext:
          {{- toYaml .Values.securityContext | nindent 10 }}
        image: "{{ .Values.image.repository }}:{{ .Values.image.tag | default .Chart.AppVersion }}"
        imagePullPolicy: {{ .Values.image.pullPolicy }}
        command: ["./relayer"]
        envFrom:
        - configMapRef:
            name: {{ include "agent-common.fullname" . }}
        - secretRef:
            name: {{ include "agent-common.fullname" . }}-secret
        - secretRef:
            name: {{ include "agent-common.fullname" . }}-relayer-secret
        env:
{{- include "agent-common.config-env-vars" (dict "config" .Values.hyperlane.relayer.config "agent_name" "relayer") | indent 10 }}
{{- $relayerChainNames := list }}
          {{- range .Values.hyperlane.relayerChains }}
{{- include "agent-common.config-env-vars" (dict "config" .signer "agent_name" "base" "key_name_prefix" (printf "CHAINS_%s_SIGNER_" (.name | upper))) | indent 10 }}
{{- $relayerChainNames = append $relayerChainNames .name }}
          {{- end }}
          - name: HYP_BASE_RELAYCHAINS
            value: {{ $relayerChainNames | join "," }}
        resources:
          {{- toYaml .Values.hyperlane.relayer.resources | nindent 10 }}
        volumeMounts:
        - name: state
          mountPath: {{ .Values.hyperlane.dbPath }}
        ports: 
        - name: metrics
          containerPort: {{ .Values.hyperlane.metrics.port }}
        {{- if .Values.hyperlane.relayer.livenessProbe }}
        {{/*
             * It's probably better to not have this hardcoded into the helm chart and to instead parametrize this -
             * however passing in multi-line strings is a total pain in Helm, especially with our setup of using
             * CLI args to set values. So for now, we'll just hardcode this in the chart and enable it only if
             * a liveness probe is asked for.
             */}}
        livenessProbe:
          exec:
            command:
            - /bin/sh
            - -c
            - |

              # Weird logging practices courtesy of https://stackoverflow.com/a/75257695
              # otherwise they get swallowed

              # Make a query to see the difference between the relayer's Solana index and the highest validator Solana index.
              # We look at the highest validator index from 5 mins ago to give the relayer some time to catch up.
              RELAYER_CMP_VALIDATOR_QUERY=$(curl 'http://prometheus-server.monitoring.svc.cluster.local/api/v1/query' --data-urlencode 'query=max by (origin) (hyperlane_last_known_message_nonce{phase="processor_loop", hyperlane_deployment="mainnet2", origin="solana"}) - max by (origin) (label_replace(hyperlane_latest_checkpoint{hyperlane_deployment="mainnet2", chain="solana"} offset 5m, "origin", "$1", "chain", "(.*)"))')
              echo "Liveness probe: relayer Solana index - validator Solana index: $RELAYER_CMP_VALIDATOR_QUERY" > /proc/1/fd/1

              # If the value is negative, the relayer is behind the validators. This env var
              # will be empty if the relayer is not behind the validators, so the presence of
              # this env var is a signal that the relayer is unhealthy.
              RELAYER_CMP_VALIDATOR_NEGATIVE=$(echo $RELAYER_CMP_VALIDATOR_QUERY | jq -r '.data.result[0].value[1] | select(. < "0")')
              echo "Liveness probe: relayer Solana index - validator Solana negative value: $RELAYER_CMP_VALIDATOR_NEGATIVE" > /proc/1/fd/1

              # Make a query to see if the relayer's Solana index is increasing over the last 5 mins.
              RELAYER_SOLANA_INDEX_DERIV_QUERY=$(curl 'http://prometheus-server.monitoring.svc.cluster.local/api/v1/query' --data-urlencode 'query=deriv(hyperlane_last_known_message_nonce{phase="processor_loop", hyperlane_deployment="mainnet2", origin="solana", remote="any"}[5m])')
              echo "Liveness probe: relayer Solana index deriv: $RELAYER_SOLANA_INDEX_DERIV" > /proc/1/fd/1

              # This env var will be empty if the value is increasing, so the presence of this
              # env var is a signal that the relayer is unhealthy.
              RELAYER_SOLANA_INDEX_DERIV_VALUE_NOT_INCREASING=$(echo $RELAYER_SOLANA_INDEX_DERIV_QUERY | jq -r '.data.result[0].value[1] | select(. < "0.0001")')
              echo "Liveness probe: relayer Solana index deriv value not increasing: $RELAYER_SOLANA_INDEX_DERIV_VALUE_NOT_INCREASING" > /proc/1/fd/1

              # Get the number of times this container has been restarted in the last 30 min.
              RELAYER_RESTARTS_30_MIN=$(curl 'http://prometheus-server.monitoring.svc.cluster.local/api/v1/query' --data-urlencode 'query=sum by (pod)(increase(kube_pod_container_status_restarts_total{exported_namespace="mainnet2", container="agent", pod=~".*relayer.*"}[30m]))')
              echo "Liveness probe: relayer restarts in the last 30 mins: $RELAYER_RESTARTS_30_MIN" > /proc/1/fd/1

              # If the relayer has restarted at all in the last 30 mins, don't restart - we want to give it a chance.
              # The presence of this env var means that the relayer has recent restarts.
              RELAYER_HAS_RECENT_RESTARTS=$(echo $RELAYER_RESTARTS_30_MIN | jq -r '.data.result[0].value[1] | select(. = "0")')
              echo "Liveness probe: does the relayer have any recent restarts: $RELAYER_HAS_NO_RECENT_RESTARTS" > /proc/1/fd/1

              # If either is empty, the relayer is healthy because the relayer is not behind the validators, or the relayer
              # is currently catching up to the validators.
              # If there are recent restarts, we don't restart to give the relayer a chance to get healthy.
              if [ -z "$RELAYER_CMP_VALIDATOR_NEGATIVE" ] || [ -z "$RELAYER_SOLANA_INDEX_DERIV_VALUE_NOT_INCREASING" ] || [ -z "RELAYER_HAS_RECENT_RESTARTS" ]; then
                echo "Liveness probe: Relayer is healthy" > /proc/1/fd/1
                exit 0
              else
                echo "Liveness probe: Relayer is unhealthy" > /proc/1/fd/1
                exit 1
              fi

          initialDelaySeconds: 300
          periodSeconds: 60
        {{- end }}
      {{- with .Values.nodeSelector }}
      nodeSelector:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.affinity }}
      affinity:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.tolerations }}
      tolerations:
        {{- toYaml . | nindent 8 }}
      {{- end }}
  volumeClaimTemplates:
  - metadata:
      name: state
    spec:
      storageClassName: {{ .Values.storage.storageClass }}
      accessModes: [ {{ .Values.storage.accessModes }} ]
      {{- if .Values.hyperlane.relayer.storage.snapshot.enabled }}
      dataSource:
        name: {{ .Values.hyperlane.relayer.storage.snapshot.name }}
        kind: VolumeSnapshot
        apiGroup: snapshot.storage.k8s.io
      {{- end }}
      resources:
        requests:
          storage: {{ .Values.hyperlane.relayer.storage.size }}
{{- end }}
